---
content_type: page
description: This section provides the schedule of reading assignments by lecture
  topic, information on the course textbook, and a list of optional supplementary
  readings.
learning_resource_types:
- Readings
ocw_type: CourseSection
title: Readings
uid: 65d5eced-f81b-12f5-0b8b-1b9b6498e820
---

Reading Assignments
-------------------

Reading assignments were taken from the course textbook:

Cover, Thomas, and Joy Thomas. _Elements of Information Theory_. 2nd ed. New York, NY: Wiley-Interscience, 2006. ISBN: 9780471241959.

{{< tableopen >}}
{{< theadopen >}}
{{< tropen >}}
{{< thopen >}}
LEC #
{{< thclose >}}
{{< thopen >}}
TOPICS
{{< thclose >}}
{{< thopen >}}
READINGS
{{< thclose >}}

{{< trclose >}}

{{< theadclose >}}
{{< tropen >}}
{{< tdopen >}}
1
{{< tdclose >}}
{{< tdopen >}}
Introduction, entropy
{{< tdclose >}}
{{< tdopen >}}
Chapter 1, sections 2.1 - 2.5
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
2
{{< tdclose >}}
{{< tdopen >}}
Jensen's inequality, data processing theorem, Fanos's inequality
{{< tdclose >}}
{{< tdopen >}}
Sections 2.6 - 2.8, 2.11
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
3
{{< tdclose >}}
{{< tdopen >}}
Different types of convergence, asymptotic equipartition property (AEP), typical set, joint typicality
{{< tdclose >}}
{{< tdopen >}}
Sections 3.1 - 3.3, 8.6
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
4
{{< tdclose >}}
{{< tdopen >}}
Entropies of stochastic processes
{{< tdclose >}}
{{< tdopen >}}
Chapter 4
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
5
{{< tdclose >}}
{{< tdopen >}}
Data compression, Kraft inequality, optimal codes
{{< tdclose >}}
{{< tdopen >}}
Sections 5.1 - 5.4
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
6
{{< tdclose >}}
{{< tdopen >}}
Huffman codes
{{< tdclose >}}
{{< tdopen >}}
Sections 5.5 - 5.7
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
7
{{< tdclose >}}
{{< tdopen >}}
Shannon-Fano-Elias codes, Slepian-Wolf
{{< tdclose >}}
{{< tdopen >}}
Sections 5.8 - 5.9, section 14 through the end of 14.4.4.1
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
8
{{< tdclose >}}
{{< tdopen >}}
Channel capacity, binary symmetric and erasure channels
{{< tdclose >}}
{{< tdopen >}}
Sections 8.1 - 8.3
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
9
{{< tdclose >}}
{{< tdopen >}}
Maximizing capacity, Blahut-Arimoto
{{< tdclose >}}
{{< tdopen >}}
 
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
10
{{< tdclose >}}
{{< tdopen >}}
The channel coding theorem
{{< tdclose >}}
{{< tdopen >}}
Sections 8.4, 8.7
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
11
{{< tdclose >}}
{{< tdopen >}}
Strong coding theorem, types of errors
{{< tdclose >}}
{{< tdopen >}}
 
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
12
{{< tdclose >}}
{{< tdopen >}}
Strong coding theorem, error exponents
{{< tdclose >}}
{{< tdopen >}}
 
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
 
{{< tdclose >}}
{{< tdopen >}}
In-class midterm
{{< tdclose >}}
{{< tdopen >}}
 
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
13
{{< tdclose >}}
{{< tdopen >}}
Fano's inequality and the converse to the coding theorem
{{< tdclose >}}
{{< tdopen >}}
Section 8.9
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
14
{{< tdclose >}}
{{< tdopen >}}
Feedback capacity
{{< tdclose >}}
{{< tdopen >}}
Section 8.12
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
15
{{< tdclose >}}
{{< tdopen >}}
Joint source channel coding
{{< tdclose >}}
{{< tdopen >}}
Section 8.13
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
16
{{< tdclose >}}
{{< tdopen >}}
Differential entropy, maximizing entropy
{{< tdclose >}}
{{< tdopen >}}
Chapter 9, sections 11.1 - 11.6
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
17
{{< tdclose >}}
{{< tdopen >}}
Additive Gaussian noise channel
{{< tdclose >}}
{{< tdopen >}}
Sections 10.1 - 10.3
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
18
{{< tdclose >}}
{{< tdopen >}}
Gaussian channels: parallel, colored noise, inter-symbol interference
{{< tdclose >}}
{{< tdopen >}}
Sections 10.4 - 10.5
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
19
{{< tdclose >}}
{{< tdopen >}}
Gaussian channels with feedback
{{< tdclose >}}
{{< tdopen >}}
Section 10.6
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
20
{{< tdclose >}}
{{< tdopen >}}
Multiple access channels
{{< tdclose >}}
{{< tdopen >}}
Sections 14.1 - 14.3
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
21
{{< tdclose >}}
{{< tdopen >}}
Broadcast channels
{{< tdclose >}}
{{< tdopen >}}
Section 14.6
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
 
{{< tdclose >}}
{{< tdopen >}}
In-class presentations (2 sessions)
{{< tdclose >}}
{{< tdopen >}}
 
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
22
{{< tdclose >}}
{{< tdopen >}}
Finite state Markov channels
{{< tdclose >}}
{{< tdopen >}}
 
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
23
{{< tdclose >}}
{{< tdopen >}}
Channel side information, wide-band channels
{{< tdclose >}}
{{< tdopen >}}
 
{{< tdclose >}}

{{< trclose >}}

{{< tableclose >}}

Supplementary Readings
----------------------

The supplementary readings are optional, except for the paper that you select as part of your project. The supplementary readings are coded for difficulty. One star: Accessible. Two stars: Requires significant mathematical maturity. Three stars: Expert level.

\[\* Lectures 4-5\] Elias, Peter. "Predictive Coding: Part I." _IRE Transactions: Information Theory_ 1, no. 16 (1955): 16-24.

\[\* Lecture 6\] Huffman, David. "A Method for the Construction of Minimum-Redundancy Codes." _Proceedings of the IRE_ 40, no. 9 (1952): 1098-1101.

\[\*\* Lecture 7\] Slepian, David, and Jack Wolf. "Noiseless Coding of Correlated Information Sources." _IEEE Transactions on Information Theory_ 19, no. 4 (1973): 471-480.

\[\*\* Lecture 7\] Elias, Peter. "Predictive Coding: Part II." _IRE Transactions: Information Theory_ 1, no. 16 (1955): 24-33.

\[\*\* Lecture 7\] Gallagher, Robert. "Variations on a Theme by Huffman." _IEEE Transactions on Information Theory_ 24, no. 6 (1978): 668-674.

\[\*\* Lectures 10-12\] Gallagher, Robert. "A Simple Derivation of the Coding Theorem and Some Applications." _IEEE Transactions on Information Theory_ 11, no. 1 (1965): 3-18.

\[\* Lectures 14, 16-20\] Cover, Thomas. "The Role of Feedback in Communication." In _Performance Limits in Communication Theory and Practice_. Edited by J. K. Skwirzynski. New York, NY: Springer, 1988, pp. 225-235. ISBN: 9789024736959.

\[\*\* Lecture 20\] El Gamal, Abbas, and Thomas Cover. "Multiple User Information Theory." _Proceedings of the IEEE_ 68, no. 12 (1980): 1466-1483.

\[\*\* Lecture 20\] Cover, Thomas, Abbas El Gamal, and Masoud Salehi. "Multiple Access Channels with Arbitrarily Correlated Sources." _IEEE Transactions on Information Theory_ 26, no. 6 (1980): 648-657.

\[\*\* Lecture 20\] Gallagher, Robert. "A Perspective on Multiaccess Channels." _IEEE Transactions on Information Theory_ 31, no. 2 (1985): 124-142.

\[\*\* Lecture 21\] Cover, Thomas. "Comments on Broadcast Channels." _IEEE Transactions on Information Theory_ 44, no. 6 (1998): 2524-2530.

\[\*\* Lecture 21\] Bergmans, Patrick, and Thomas Cover. "Cooperative Broadcasting." _IEEE Transactions on Information Theory_ 20, no. 3 (1974): 317-324.

\[\*\*\* Lecture 21\] Weingarten, Hanan, Yosef Steinberg, and Shlomo Shamai (Shitz). "The Capacity Region of the Gaussian Multiple-Input Multiple-Output Broadcast Channel." _IEEE Transactions on Information Theory_ 52, no. 9 (2006): 3936-3964.

\[\*\* Lectures 21-22\] Jindal, Nihar, Sriram Vishwanath, and Andrea Goldsmith. "On the Duality of Gaussian Multiple-Access and Broadcast Channels." _IEEE Transactions on Information Theory_ 50, no. 5 (2004): 768-783.

\[\*\*\* Lectures 22-23\] Goldsmith, Andrea, and Pravin Varaiya. "Capacity, Mutual Information, and Coding for Finite-State Markov Channels." _IEEE Transactions on Information Theory_ 42, no. 3 (1996): 868-886.

\[\*\*\* Lecture 23\] Médard, Muriel, and Robert Gallagher. "Bandwidth Scaling for Fading Multipath Channels." _IEEE Transactions on Information Theory_ 48, no. 4 (2002): 840-852.